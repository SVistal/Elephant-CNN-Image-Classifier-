{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b02601-c99d-43ff-9bff-d08b1e5a2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuring memory growth for GPUs\n",
    "# Keep GPU from using up all memory\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Loading and preprocessing training data\n",
    "data = tf.keras.utils.image_dataset_from_directory(\"train\")\n",
    "data = data.map(lambda x, y: (x / 255, y))  # Scaling the image data between 0 and 1\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "train_size = int(len(data) * 0.8) # Train 80% of data\n",
    "val_size = int(len(data) * 0.2) + 1 # Leave 20% to validate(test)\n",
    "train_data = data.take(train_size) \n",
    "val_data = data.skip(train_size).take(val_size) #validation data does not overlap training\n",
    "\n",
    "# Checking minimum value of the first batch of data\n",
    "data.as_numpy_iterator().next()[0].min()\n",
    "\n",
    "# Obtaining a batch of data for visualization\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()\n",
    "\n",
    "# Creating subplots for visualizing the batch of images\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20)) # four plots in a single row 20X20 inches\n",
    "for idx, img in enumerate(batch[0][:4]): # sets up loop for first 4 images in the batch array\n",
    "    ax[idx].imshow(img) # Shows images\n",
    "    ax[idx].title.set_text(batch[1][idx]) # Gives title\n",
    "\n",
    "# Loading and preprocessing test data\n",
    "test_dir = tf.keras.utils.image_dataset_from_directory(\"test\") # Gets images from \"test\" folder\n",
    "test_data = test_dir.map(lambda x, y: (x / 255, y)) # Scale images between 0 & 1\n",
    "\n",
    "# Configuring AUTOTUNE for performance optimization of data\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Caching and prefetching the training, validation, and test data\n",
    "# Minimizing I/O latency and maximizing GPU or CPU utilization\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_data = test_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Creating the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3)), #creates a 2D convolutional laye\n",
    "    MaxPooling2D(), #reduces the spatial dimensions of the input\n",
    "    Conv2D(32, (3, 3), 1, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(16, (3, 3), 1, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=\"adam\", loss=tf.losses.BinaryCrossentropy(), metrics=[\"accuracy\"]) \n",
    "\n",
    "# Training the model\n",
    "history = model.fit(train_data, epochs=20, validation_data=val_data)\n",
    "\n",
    "# Evaluating the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Visualizing the evaluation of the test model\n",
    "evaluation_results = model.evaluate(test_data)\n",
    "labels = ['Test Loss', 'Test Accuracy']\n",
    "values = [evaluation_results[0], evaluation_results[1]]\n",
    "\n",
    "plt.plot(labels, values, marker='o', color='teal')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Evaluation of Test Model')\n",
    "plt.show()\n",
    "\n",
    "# Visualizing the training history\n",
    "fig, axes = plt.subplots(2, figsize=(10, 8)) # 2 plots 10X8 inches\n",
    "fig.suptitle(\"Training History\", fontsize=20) # Title for both \n",
    "\n",
    "# First plot\n",
    "axes[0].plot(history.history[\"loss\"], color='teal', label='loss') # plots loss with color and label\n",
    "axes[0].plot(history.history[\"val_loss\"], color='orange', label='val_loss') # plot val_loss with color and label\n",
    "axes[0].set_xlabel(\"Epochs\") # Vertical label name\n",
    "axes[0].set_ylabel(\"Loss\") # Horizontal label name \n",
    "axes[0].legend(loc=\"upper right\") # location of label\n",
    "\n",
    "# Second plot\n",
    "axes[1].plot(history.history[\"accuracy\"], color='teal', label='accuracy') # plot accuracy with color and label\n",
    "axes[1].plot(history.history[\"val_accuracy\"], color='orange', label='val_accuracy') #plot val_accuracy with color and label\n",
    "axes[1].set_xlabel(\"Epochs\") # Vertical label name\n",
    "axes[1].set_ylabel(\"Accuracy\") # Horizontal label name \n",
    "axes[1].legend(loc=\"lower right\") # location of label\n",
    "\n",
    "# Displaying the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
